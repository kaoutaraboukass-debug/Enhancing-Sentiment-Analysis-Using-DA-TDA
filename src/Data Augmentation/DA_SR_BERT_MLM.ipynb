{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ol0B9CeZHlAt","outputId":"f47aaf6a-a8d1-4cbf-d652-d5b051353757","executionInfo":{"status":"ok","timestamp":1755344257932,"user_tz":-60,"elapsed":4314,"user":{"displayName":"kaoutar ABOUKASS","userId":"08415247757709328621"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"]}],"source":["pip install openpyxl"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForMaskedLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"SI2M-Lab/DarijaBERT\")\n","model = AutoModelForMaskedLM.from_pretrained(\"SI2M-Lab/DarijaBERT\")\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["34eb86bfd1d34e24bed6edc39b28a12f","5d82e6c4496e4744b0dade2c07719da8","6f70a1a186064a59b9b26588e8e50e27","017b8759144c48eebdf17c78a0ee7a20","18648766ddb04ecd84058ca63107c0fc","cfc18ad8262a4b92b62482e682472e0b","138002c91766454b8fa8ae8a5fad6520","5403fee346594d48b29ee7817299914e","7df4c5be5051442bbf00ffe5a9f26be5","1ebb38f5556e4698a2047f564dbaa70d","023e9869f32540de8f31bd27f3001419","9ca0d84b9c27415992fc8cbd10a84b3c","db94c850bb724aa1b4d1bd154ac3f536","0c8ae64fcd44452b8109f174f53f320c","25d9e77aae094043b95583602a435e1b","b42a8b8d67fa419da6457d5c2ac264e6","ea8e732f584844e7a6b58d7c96480174","fd39151fb3cc4780b76872d8dbd90a12","ed1e1b7599774a1ab34699e2f8587704","b7e34910785446329509fa9b8c101028","482e655ba683493189916e92470735d0","775afcb906a44814a1a01efc657a805a","99783acd093f4c3d8e8bd46bdf0c0109","26ccad5fd512454c9b11bf0aaa8500f9","a03112f3ea6d4a1a9f70e26e9f17a30d","43ae388bd06644cf9936af5aeeadcf1b","5c7893014fa7461cb902bc6e29d699fe","7a759aabc9b241b691efb91bfcff0d7c","010075a36f2a4dd3beade98b803857bb","aaf5849e9aa8407abce1b0baf0815437","ae9d3434dda54ae8ba9cb320ec22d0ea","848fec4beba44da381cce4f96753635a","473a35032edc4040bd47ccad96c927d5","f0d4601e722d4cc18767f297df3a50bc","8e2e1f0232504971bace02f300cfbfa8","bc23647234144d15accb405ef547d0a1","015550ed367d4649b4cbc67f9a3d7696","d3ff7cbafcd641859e963f33c52cad72","3f0c11cc24604a9ca4ab65b00b6ff9bf","c0a5dd6ba13a42c7bc5352525cae8252","306c01961cfd48f990ec767940ff4ffc","8d9d71f7d29349d5ba1c813821619dad","f9b7eb84c3cb4eadadd636bab9c664b1","49eaff4381ef4ab2a8df3a398b346ff0","7f085b7251d04479820f443ff8cba399","a18087944f304516ae0f28f4e959a8af","59dafbea904048f7aa51dacfcb224407","0433b97bc18649fcbd6d04488dbeccd7","1a90294eb3d842049a5869f7fd4dab0d","7dbd31d9ad3b461b9d7b496e9f8b2ffa","e4a26b26608e449c99e3ef50491cd823","c319cef1273545a4841e60bdf3f3734e","bfcc98c0ccd04156a4790452c257a807","fcd2272acfcc44c4ace8accff98af1f9","9d0cca5cff12407d95b5444f7176d6b4","5c48c34a0a3f4ef5baaffc8a3234a486","32b4308af888455dad7d329ea43f4801","60683cfef6ec45cea3d66425b3e0c723","e49147e8a6f04837b0199978b5dfbb0c","66075dcd861b4a7985be2bd5fb1eeb8f","857b57afed7044c5840f8c20b0f38178","a157320d92ff44a18f3402a34810311e","b7ec084c80fa4cd38d56bc7b33f7816b","f3aeabd033b9468b85ace98fa477d980","8b5b26e0c9f445a38e95672e737b7873","fab90c675b9b4182813afb8fcbfb9dea"]},"id":"0YOtCBwmH3SX","outputId":"75f0a3be-911f-4520-901b-dd57e36f0052","executionInfo":{"status":"ok","timestamp":1755344313059,"user_tz":-60,"elapsed":55113,"user":{"displayName":"kaoutar ABOUKASS","userId":"08415247757709328621"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/307 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34eb86bfd1d34e24bed6edc39b28a12f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ca0d84b9c27415992fc8cbd10a84b3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99783acd093f4c3d8e8bd46bdf0c0109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d4601e722d4cc18767f297df3a50bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f085b7251d04479820f443ff8cba399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/836M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c48c34a0a3f4ef5baaffc8a3234a486"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(80000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (transform_act_fn): GELUActivation()\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=768, out_features=80000, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import pandas as pd\n","\n","ds = pd.read_excel(r'/content/sample_data/neg_comments.xlsx')\n","comments = ds['Comment'].tolist()"],"metadata":{"id":"LmZk7Er5H7ui"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PmQBIyRWmLfm"},"source":["# ***1. Synonym Replacement***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlGcTdDNy-5y"},"outputs":[],"source":["caracters = {\"&\", \"/\", \".\", \",\", \":\", \";\", \"!\", \"?\", \"-\", \"_\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"}\n","\n","def not_str_token(token):\n","    #sous_tokens\n","    if token.startswith(\"##\"):\n","        return True\n","    if token.endswith(\"##\"):\n","        return True\n","    if token.isdigit():\n","        return True\n","    if not re.fullmatch(r'[\\u0600-\\u06FF]+', token):\n","        return True\n","    # caractÃ¨res\n","    if token in caracters:\n","        return True\n","    #emoticons\n","    if all(not c.isalnum() for c in token):\n","        return True\n","    return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZyI_eV-d79Y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2a3e6d20-b24a-4e32-dac5-574ca5616653","executionInfo":{"status":"ok","timestamp":1755344318868,"user_tz":-60,"elapsed":4948,"user":{"displayName":"kaoutar ABOUKASS","userId":"08415247757709328621"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}],"source":["from transformers import pipeline\n","import re\n","import random\n","import torch\n","\n","pipe = pipeline(\"fill-mask\", model=\"SI2M-Lab/DarijaBERT\")\n","\n","def get_predicted_comments(comment):\n","\n","  comment = re.sub(r'[^\\w\\s]', '', comment)\n","  previous_word = \" \"\n","  next_word = \" \"\n","  comment_words = comment.split()\n","  #print(comment_words)\n","\n","  # SÃ©lection d'un indice alÃ©atoire\n","  pos = random.randint(0, len(comment_words) - 1)\n","  if pos != 0:\n","    previous_word=comment_words[pos-1]\n","\n","  elif pos != len(comment_words)-1 :\n","    next_word=comment_words[pos+1]\n","\n","  #masker le mot choisi\n","  masked_word=comment_words[pos]\n","\n","  comment_words[pos] = \"[MASK]\"\n","\n","  input_comment = ' '.join(comment_words)\n","  #print(input_comment)\n","\n","  resultats = pipe(input_comment,top_k=5)\n","  step1 = pipe(input_comment,top_k=15)[0]['sequence']\n","  comment_variances = []\n","\n","  filtered = [result for result in resultats\n","              if not not_str_token(result['token_str'])\n","              and result['token_str'] != masked_word\n","              and result['token_str'] != next_word\n","              and result['token_str'] != previous_word]\n","\n","  for f in filtered:\n","     comment_variances.append(f['sequence'])\n","     #print(f\"{f['sequence']} â score: {f['score']:.4f}\")\n","  return comment_variances"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKfBAa2UTHfk"},"outputs":[],"source":["def get_comment_embedding(comment):\n","\n","    inputs = tokenizer(comment, return_tensors=\"pt\", padding=True, truncation=True)\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    model.config.output_hidden_states = True\n","    embeddings = outputs.hidden_states[-1]  # [batch_size, seq_len, hidden_dim]\n","\n","    # Ignorer CLS et SEP et prendre la moyenne des embeddings restants\n","    mask = inputs[\"attention_mask\"].unsqueeze(-1)  # [batch_size, seq_len, 1]\n","    sum_embeddings = torch.sum(embeddings * mask, dim=1)\n","    mean_embedding = sum_embeddings / mask.sum(dim=1)  # Moyenne pondÃ©rÃ©e\n","\n","    #Retourne l'embedding moyen d'une phrase aprÃ¨s passage par le modÃ¨le darija bert\n","    return mean_embedding.squeeze(0)  # Retirer la dimension batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQES38IrqQ_p"},"outputs":[],"source":["#maintenant qu'on 5 variantes du commentaire, on va calculer cosin_dist entre le commentaire originale et les phrases augmentÃ©es\n","#on va par la suite conserver les phrases ayant une cosine similarity supÃ©rieur Ã  90%\n","from torch.nn.functional import cosine_similarity\n","\n","\n","def get_Best_Variances(comment,comment_variances):\n","\n","    original_embedding = get_comment_embedding(comment)\n","    best_score=0\n","    best_comment=comment\n","    for cmt in comment_variances:\n","\n","        cmt_vr_embedding = get_comment_embedding(cmt)\n","        score = cosine_similarity(original_embedding, cmt_vr_embedding,dim=0).item()\n","\n","        #print(\"variant\", cmt, \"score = \", score)\n","        if score > best_score:\n","            best_score = score\n","            #print(score)\n","            best_comment = cmt\n","    if best_score >= 0.90:\n","      return best_comment\n","    else:\n","      return \"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpFuQTL8C7-E"},"outputs":[],"source":["\n","def SynonmReplacement(comment):\n","\n","  comment_variances = get_predicted_comments(comment)\n","  augmented_comment = get_Best_Variances(comment,comment_variances)\n","  return augmented_comment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThWoWxeTiQEt"},"outputs":[],"source":["augmentedComments_by_SR =[]\n","for comment in comments:\n","    augmentedcomment = SynonmReplacement(comment)\n","    if augmentedcomment != \"\":\n","      augmentedComments_by_SR.append(augmentedcomment)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qlEY3C0Mi1v"},"outputs":[],"source":["data = { \"Augmented Comment\": augmentedComments_by_SR}\n","df = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KStgIIkOFLpU"},"outputs":[],"source":["df.to_excel('augmentednegcomments_bySR.xlsx')"]}]}