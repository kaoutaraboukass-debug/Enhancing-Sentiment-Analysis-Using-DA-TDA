{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPyjtzTTAVZvnAnY+NL5ezk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwGoFbV9MeKN","executionInfo":{"status":"ok","timestamp":1755339987435,"user_tz":-60,"elapsed":5049,"user":{"displayName":"kaoutar ABOUKASS","userId":"08415247757709328621"}},"outputId":"bc5bce6b-a49e-4da6-d96f-1e3d6b15831f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"]}],"source":["pip install openpyxl"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForMaskedLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"SI2M-Lab/DarijaBERT\")\n","model = AutoModelForMaskedLM.from_pretrained(\"SI2M-Lab/DarijaBERT\")\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f369b5f55982430d874b7767159faee1","aea3add253ce4ceba9e90d9f2477afac","fe028e37cc5f48dc80ee75541c7f1bf1","5882cfa6ca964b37b863f09d4dd9ffc5","8e09d4988e5a4a52afe4df9e599b59f5","830b2a9e11704125b5782cfc493c97f3","814c5585ecc644659f046880d1f7b323","319d286246d741b091ed8cc62787798e","bc125db2b1eb4b509cc3fd8d17e21be5","1cc0d2ae636941dda82c73f24660f1e0","c7dddfac1d604afaa4f9294a13fa7eac","1aa6c520001f4fab9b5a73660234171c","e8e5c85542ea4e1fa05a6ec153535a90","55b28ba799fe4f248eb2978206546dac","b910f3cbf0d9454a9b14bf942e496638","17d0be666f3245848cda533bd27f9b2e","da6b7a898c06429494f293d11ecfb7c7","17f26f52c29e4e93a3b667b4965a231c","af1042b02ed043859948ba827b59e9fe","d8d2ee19537f4246aec29184902b40a6","53def273980c4f6aba20241ce346339f","f782c00772934fa7b2a4c04dc3b051b1","59d79a924e1d48db8c4f9cfa6bd8990d","1de042a416df4da799ad238450b3f6fa","18c0105839684bf3a09ec57f3323b343","93633d73151e459e9a4f7d00a3588616","0cff335afcbc4a4eacadf696470e19e9","a39c98fd40eb4c05bef8107fc06a933b","02ef49870acb42ad921bccb5145b5d04","eef5323a6bea4ec3820a82fa1518d57d","abc0e4e5f5ed450a95e50f9018d20023","f797ff66a63643acb845c09be2ba07b2","acb1096a99fc46c7b24eb65007ccc3ee","eec5c2ff906543fe8a02526115e06314","a64549b46ec44566b8cf1f45777bb42e","f092842e997840198ca9a8ebdb4bdc3f","56f2cadd958b486da0a7bc0a797ccdd3","14f586b5cdc54af785109d9979820ec4","b72f908875bd4e0b92d8f5f0b9b636ce","86190113337743fd95cfddb184934502","d8931159558d43ffae42e25fd47b6e49","dd056f75563843e0b24253438a3b5440","be8d088afdb548b2a803f79c176d84e4","7abd969d1e2f43c7a90ea309e5252f69","9671a4461822435380d2d9ae150d2d0e","49106eef79ef4dc79b93e7711e1cc22b","edbd98cb070a43e09ce67828fae0ae4d","680aa74546b74226bf6abf90a0e343cc","33c74e3812614811a2b33b0469541aab","bad826c1b5d44abb803203e235435b54","b18bb40f87f04c0590e20e5710a86365","535e92163a994eeabadb17834aa171ca","4f0f6a73944e48009841ec02b18a5d9a","fcdb957ebbae49e485ab357cb1b1ad76","3e54f74544c24720a83e4c0ee43369b6","114d43e41b15403387bf7a00338475df","fd4a45a459314098a682ccd985ac9c15","852d9d47b1014be3bd439490693d7bcd","fc91b24d9df7483fb144eb1faf41054b","bdf9a53a0a704ee88c17fee167863e82","a128c2e3fa4b4f989e461b2ad8156145","c012f775b90948f3b0f7bb6145d3e9e4","4157d747c446434cab42969f6fa5a34a","3805356e46694ee88279ca24963a4503","663b546856f6498384e2ff609b9ec588","c98f0fbda4c04b88bf22f1818b108630"]},"id":"_EBmsCgYMnXO","executionInfo":{"status":"ok","timestamp":1755340045349,"user_tz":-60,"elapsed":57891,"user":{"displayName":"kaoutar ABOUKASS","userId":"08415247757709328621"}},"outputId":"8aa2baff-aef0-4e34-f8ad-683f88d3b72c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/307 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f369b5f55982430d874b7767159faee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aa6c520001f4fab9b5a73660234171c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59d79a924e1d48db8c4f9cfa6bd8990d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec5c2ff906543fe8a02526115e06314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9671a4461822435380d2d9ae150d2d0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/836M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"114d43e41b15403387bf7a00338475df"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(80000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (transform_act_fn): GELUActivation()\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=768, out_features=80000, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import pandas as pd\n","\n","ds = pd.read_excel(r'/content/sample_data/neg_comments.xlsx')\n","comments = ds['Comment'].tolist()"],"metadata":{"id":"80Fh04aIMpTR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0L7wDo79p48w"},"source":["# ***3. Random Insertion***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlGcTdDNy-5y"},"outputs":[],"source":["caracters = {\"&\", \"/\", \".\", \",\", \":\", \";\", \"!\", \"?\", \"-\", \"_\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"}\n","\n","def not_str_token(token):\n","    #sous_tokens\n","    if token.startswith(\"##\"):\n","        return True\n","    if token.endswith(\"##\"):\n","        return True\n","    if token.isdigit():\n","        return True\n","    if not re.fullmatch(r'[\\u0600-\\u06FF]+', token):\n","        return True\n","    # caractères\n","    if token in caracters:\n","        return True\n","    #emoticons\n","    if all(not c.isalnum() for c in token):\n","        return True\n","    return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WS3tF769_vgJ"},"outputs":[],"source":["from transformers import pipeline\n","import re\n","import random\n","import torch\n","\n","pipe = pipeline(\"fill-mask\", model=\"SI2M-Lab/DarijaBERT\")\n","\n","def get_predicted_commentsByInsertion(comment):\n","\n","  comment = re.sub(r'[^\\w\\s]', '', comment)\n","  previous_word = \" \"\n","  next_word = \" \"\n","  comment_words = comment.split()\n","  #print(comment_words)\n","\n","  # Sélection d'un indice aléatoire\n","  pos = random.randint(0, len(comment_words) - 1)\n","  if pos != 0:\n","    previous_word=comment_words[pos-1]\n","\n","  elif pos != len(comment_words)-1 :\n","    next_word=comment_words[pos+1]\n","\n","  #ajouter token maské\n","  comment_words.insert(pos,\"[MASK]\")\n","\n","  input_comment = ' '.join(comment_words)\n","  #print(input_comment)\n","\n","  resultats = pipe(input_comment,top_k=5)\n","  step1 = pipe(input_comment,top_k=15)[0]['sequence']\n","  comment_variances = []\n","\n","  filtered = [result for result in resultats\n","              if not not_str_token(result['token_str'])\n","              and result['token_str'] != next_word\n","              and result['token_str'] != previous_word]\n","\n","  for f in filtered:\n","     comment_variances.append(f['sequence'])\n","     #print(f\"{f['sequence']} → score: {f['score']:.4f}\")\n","  return comment_variances"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKfBAa2UTHfk"},"outputs":[],"source":["def get_comment_embedding(comment):\n","\n","    inputs = tokenizer(comment, return_tensors=\"pt\", padding=True, truncation=True)\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    model.config.output_hidden_states = True\n","    embeddings = outputs.hidden_states[-1]  # [batch_size, seq_len, hidden_dim]\n","\n","    # Ignorer CLS et SEP et prendre la moyenne des embeddings restants\n","    mask = inputs[\"attention_mask\"].unsqueeze(-1)  # [batch_size, seq_len, 1]\n","    sum_embeddings = torch.sum(embeddings * mask, dim=1)\n","    mean_embedding = sum_embeddings / mask.sum(dim=1)  # Moyenne pondérée\n","\n","    #Retourne l'embedding moyen d'une phrase après passage par le modèle darija bert\n","    return mean_embedding.squeeze(0)  # Retirer la dimension batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQES38IrqQ_p"},"outputs":[],"source":["#maintenant qu'on 5 variantes du commentaire, on va calculer cosin_dist entre le commentaire originale et les phrases augmentées\n","#on va par la suite conserver les phrases ayant une cos_dist sup à 80%\n","from torch.nn.functional import cosine_similarity\n","\n","\n","def get_Best_Variances(comment,comment_variances):\n","\n","    original_embedding = get_comment_embedding(comment)\n","    best_score=0\n","    best_comment=comment\n","    for cmt in comment_variances:\n","\n","        cmt_vr_embedding = get_comment_embedding(cmt)\n","        score = cosine_similarity(original_embedding, cmt_vr_embedding,dim=0).item()\n","\n","        #print(\"variant\", cmt, \"score = \", score)\n","        if score > best_score:\n","            best_score = score\n","            #print(score)\n","            best_comment = cmt\n","    if best_score >= 0.90:\n","      return best_comment\n","    else:\n","      return \"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFCg6GdLAXd5"},"outputs":[],"source":["def random_insertion(comment):\n","  comment_variances = get_predicted_commentsByInsertion(comment)\n","  augmented_comment = get_Best_Variances(comment,comment_variances)\n","  return augmented_comment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEuCHDl7A2Fa"},"outputs":[],"source":["augmentedComments_by_RI =[]\n","for comment in comments:\n","    augmentedcomment = random_insertion(comment)\n","    if augmentedcomment != \"\":\n","      augmentedComments_by_RI.append(augmentedcomment)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmJNgx9qBbpx"},"outputs":[],"source":["RI_data = { \"Augmented Comment\": augmentedComments_by_RI}\n","df_RI = pd.DataFrame(RI_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0HUrT1AnBy64"},"outputs":[],"source":["df_RI.to_excel('augmentednegcomments_byRI.xlsx')"]}]}